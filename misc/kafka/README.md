# kafka Migration Tool

This tool migrates the service configuration and metadata of Kafka from DCOS to DKP.
## Prerequisites

- `python3` installed in the environment
- DC/OS CLI `dcos` setup to talk to a DC/OS Cluster
- DC/OS Kafka CLI `dcos package install kafka --cli` setup to talk to Kafka service.
- Kubernetes CLI `kubectl` setup to talk to a konvoy cluster
- Kudo CLI `kubectl-kudo` setup to install operators
- Make sure Kudo is initiated `kubectl kudo init`
- Basic knowledge of kubernetes, kudo and kafka.
- Script is tested to work in Linux based environments.


## Commands

Python file located at `misc/kafka/scripts/main.py` is the main entrypoint for the tooling used to migrate kafka. Run `cd misc/kafka/scripts` to move to scripts directory. The --help flag describes the steps involved in migration:

```
➜ python3 main.py --help

usage: main.py [-h] [--version] {backup,install} ...

positional arguments:
  {backup,install}  sub-commands available
    backup          Backup the DC/OS package configurations and data
    install         Translate the DC/OS based configs to KUDO based configs and print install instructions.

optional arguments:
  -h, --help        show this help message and exit
  --version         show program's version number and exit
``` 

### Overview 
Kafka configuration migration is performed using `backup` and `install` commands.

1. Backup the DC/OS Kafka configurations locally, using the `backup` command.
2. Install KUDO Kafka on DKP by translating the above downloaded configuration and adding other customization, using `install` command.

These steps are explained in following steps:

### `1. Backup`

By providing a service name or app-id (defaults to `/kafka`), all the configuration can be downloaded to local file system and data can be backed up to S3.

```
➜ python3 main.py backup --help

usage: main.py backup [-h] [-t TARGET_DIR] [--app-id APP_ID] [--only-conf ONLY_CONF] [--app-version APP_VERSION]

optional arguments:
  -h, --help            show this help message and exit
  -t TARGET_DIR, --target-dir TARGET_DIR
                        Folder to hold configuration of running DC/OS Kafka service (defaults to ./kafka_home)
  --app-id APP_ID       Service Name (defaults to kafka)
  --only-conf ONLY_CONF
                        Set True if only service configuration is required, no data backup (defaults to true)
  --app-version APP_VERSION
                        Service Version (defaults to 2.5.1-1.3.3)

```

`TARGET_DIR` defaults to `$(pwd)/kafka_home`. The `--only-conf` option is set to `true` as the kafka migration utility currently only supports configuration migration.


### `2. Install`

The `install` command generates a `TARGET_FILE` (that defaults to `$(pwd)/kafka_home/params.yml` ) and prints instructions on how to use it to install in KUDO Kafka on DKP. Other parameters such as `namespace` and `instance` have sensible defaults in accordance with the upstream kudo operator definition but can be customized.

```
➜ python3 main.py install --help

usage: main.py install [-h] [-c CONFIG_FILE] [-t TARGET_FILE] [--namespace NAMESPACE] [--instance INSTANCE] [--operator-version OPERATOR_VERSION]

optional arguments:
  -h, --help            show this help message and exit
  -c CONFIG_FILE, --config-file CONFIG_FILE
                        Path of the kafka env file generated by backup command. (defaults to ./kafka_home/kafka_env.json)
  -t TARGET_FILE, --target-file TARGET_FILE
                        Path of the target params file (defaults to ./kafka_home/params.yml)
  --namespace NAMESPACE
                        Namespace of the kafka pods (defaults to default)
  --instance INSTANCE   Name of the KUDO Kafka installation (defaults to kafka-instance)
  --operator-version OPERATOR_VERSION
                        Kudo Kafka version (defaults to 1.3.3)
```

Once the `backup` command is successfull, installing KUDO kafka on DKP with default namespace, operator-version and instance would look like
```
➜ python3 main.py install

[2021-03-11 17:10:08,451]  INFO {main.py:19} - Translating Mesos configurations to K8s configurations
[2021-03-11 17:10:08,451]  INFO {translate.py:116} - Using "./kafka_home/kafka_env.json" file to migrate to kubernetes configuration at "./kafka_home/params.yml"
./kafka_home/params.yml
--------------------------------------------------
Install KUDO Zookeeper
--------------------------------------------------
Run the following command to install KUDO Zookeeper on DKP: 
kubectl kudo install \
    --namespace default \
    --instance zookeeper-instance \
    zookeeper

--------------------------------------------------
Run the following command to check the status: 
kubectl kudo plan status \
    --namespace default \
    --instance zookeeper-instance

--------------------------------------------------
Make sure plan shows COMPELTE, before proceeding further.
--------------------------------------------------


--------------------------------------------------
Install KUDO Kafka
--------------------------------------------------
WARNING: ALL THE PARAMETERS ARE GENERATED AS PER THE DCOS VERSION OF THE SERVICE, IT MIGHT NOT BE THE BEST FOR K8s.
SO BEFORE INSTALLING THE SERVICE PLEASE OPEN A TARGET FILE (./kafka_home/params.yml) AND MODIFY VALUES AS PER THE AVAILABILITY ON THE K8s CLUSTER.
SPECIALLY VALUES OF THESE FIELDS SHOULD BE ADJUSTED AS PER THE CLUSTER:
BROKER_COUNT
BROKER_CPUS
BROKER_MEM
DISK_SIZE
--------------------------------------------------
Run the following command to install KUDO Kafka on DKP: 
kubectl kudo install \
    --namespace default \
    --instance kafka-instance \
    --parameter-file ./kafka_home/params.yml \
    --operator-version 1.3.3 \
    kafka

--------------------------------------------------
Run the following command to check the status: 
kubectl kudo plan status \
    --namespace default \
    --instance kafka-instance

--------------------------------------------------
Make sure plan shows COMPELTE, before proceeding further.
--------------------------------------------------
```

### `3. Migrate`

KUDO Kafka comes with [MirrorMaker](https://cwiki.apache.org/confluence/display/KAFKA/KIP-382%3A+MirrorMaker+2.0) which enables replicating data across two Kafka clusters. The `migrate` command takes the required argument `--dcos-bootstrap-servers` along with the `--namespace` and `--instance` parameters to print the migration command. Use this command once the KUDO Kafka brokers are up and running. It is necessary that your source kafka cluster brokers are accessible from destination kafka cluster brokers.

```
➜ python3 main.py migrate --help

usage: main.py migrate [-h] [--namespace NAMESPACE] [--instance INSTANCE] [--dcos-bootstrap-servers DCOS_BOOTSTRAP_SERVERS]

optional arguments:
  -h, --help            show this help message and exit
  --namespace NAMESPACE
                        Namespace of the kafka pods (defaults to default)
  --instance INSTANCE   Name of the Kafka Kudo installation (defaults to kafka-instance)
  --dcos-bootstrap-servers DCOS_BOOTSTRAP_SERVERS
                        Externally exposed DC/OS Kafka bootstrap servers.
```
To start the migtation, we need to update the installed KUDO Kafka instances by enabling the MirrorMaker. We get the final migration command by running the following command.

```
➜ python3 main.py migrate --dcos-bootstrap-servers=other-server-1.example.com,other-server-2.example.com

--------------------------------------------------
Make sure the KUDO Kakfka installation plan shows COMPELTE, before proceeding for migration.
--------------------------------------------------
Run the following command to start migration of your Kafka cluster 
    kubectl kudo update --instance=kafka-instance --namespace=default \
    -p MIRROR_MAKER_ENABLED=true \
    -p MIRROR_MAKER_EXTERNAL_BOOTSTRAP_SERVERS=other-server-1.example.com,other-server-2.example.com \
    -p MIRROR_MAKER_EXTERNAL_CLUSTER_TYPE=DESTINATION

```

Pleas refer to KUDO Kafka [docs](https://kudo.dev/docs/runbooks/kafka/mirrormaker.html#starting-mirrormaker) for more details.
